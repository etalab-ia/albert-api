<div id="toc">
  <ul align="center" style="list-style: none">
    <summary><h1>ğŸš€ Albert API</h1></summary>

*French version below*

**Enterprise-ready Generative AI API Gateway | Open Source | Sovereign Infrastructure**

**Developed by the French Government ğŸ‡«ğŸ‡·**

[![Code Coverage](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/etalab-ia/albert-api/refs/heads/main/.github/badges/coverage.json)](https://github.com/etalab-ia/albert-api)

[**Documentation**](https://albert.api.etalab.gouv.fr/documentation) | [**Playground**](https://albert.api.etalab.gouv.fr/playground) | [**API Status**](https://albert.api.etalab.gouv.fr/status) | [**Swagger**](https://albert.api.etalab.gouv.fr/swagger)

  </ul>
</div>


## ğŸš€ Quickstart

### Run Albert-API with basic functionalities (docker)
Albert-API is configured by default to launch via Docker the API, the playground and a PostgreSQL database, and to connect to a small model made available for free. Simply run:
```bash
make docker-compose-quickstart-up
```

To stop the services, run
```bash
make docker-compose-quickstart-down
```

### Configure Albert-API
Albert-API supports OpenAI and Albert-API models. To configure them, run:
```bash
cp config.example.yml config.yml
```

And modify the `models` section in the `config.yml` file:

```yaml
models:
  - id: albert-large
    type: text-generation
    owned_by: test
    aliases: ["mistralai/Mistral-Small-3.1-24B-Instruct-2503"]
    clients:
      - model: mistralai/Mistral-Small-3.1-24B-Instruct-2503
        type: albert
        args:
          api_url: ${ALBERT_API_URL:-https://albert.api.etalab.gouv.fr}
          api_key: ${ALBERT_API_KEY}
          timeout: 120
  - id: my-language-model
    type: text-generation
    clients:
      - model: gpt-3.5-turbo
        type: openai
        params:
          total: 70
          active: 70
          zone: WOR
        args:
          api_url: https://api.openai.com
          api_key: ${OPENAI_API_KEY}
          timeout: 60
```
The API keys can be defined directement in the `config.yml` file or in a `.env` file

```bash
cp .env.example .env

echo 'ALBERT_API_KEY=my_albert_api_key' >> .env
echo 'OPENAI_API_KEY=my_openai_api_key' >> .env
```

Finally, run the application:
```bash
make docker-compose-albert-api-up
```

To stop the application, run:
```bash
make docker-compose-albert-api-down
```


## Running locally

### Prerequisites
- Python 3.8+
- Docker and Docker Compose

### Installation

#### 1. Installing dependencies

```bash
make install
```

#### 2. Configuration

Albert-API supports OpenAI and Albert-API models, defined in the `config.yml` file :
```bash
cp config.example.yml config.yml
```

And modify the `models` section in the `config.yml` file:

```yaml
models:
  - id: albert-large
    type: text-generation
    owned_by: test
    aliases: ["mistralai/Mistral-Small-3.1-24B-Instruct-2503"]
    clients:
      - model: mistralai/Mistral-Small-3.1-24B-Instruct-2503
        type: albert
        args:
          api_url: ${ALBERT_API_URL:-https://albert.api.etalab.gouv.fr}
          api_key: ${ALBERT_API_KEY}
          timeout: 120
  - id: my-language-model
    type: text-generation
    clients:
      - model: gpt-3.5-turbo
        type: openai
        params:
          total: 70
          active: 70
          zone: WOR
        args:
          api_url: https://api.openai.com
          api_key: ${OPENAI_API_KEY}
          timeout: 60
```
The API keys can be defined directement in the `config.yml` file or in a `.env` file

```bash
cp .env.example .env

echo 'ALBERT_API_KEY=my_albert_api_key' >> .env
echo 'OPENAI_API_KEY=my_openai_api_key' >> .env
```

### Running

#### Option 1: Full launch with Docker

```bash
# Start all services (API, playground and external services)
make docker-compose-albert-api-up
# Stop all services
make docker-compose-albert-api-down
```

#### Option 2: Local development

```bash
# 1. Start only external services (Redis, Qdrant, PostgreSQL, MCP Bridge)
make docker-compose-services-up

# 2. Launch the API (in one terminal)
make run-api

# 3. Launch the user interface (in another terminal)
make run-ui
```

## ğŸ“« API Gateway

## ğŸ”¥ Why Albert API?

Albert API is an **enterprise-ready open-source gateway** for deploying **generative AI models** on your infrastructure:

* ğŸš¦ **Robust API Gateway:** Load balancing, authentication, and seamless integration with OpenAI, vLLM, HuggingFace TEI.
* ğŸ“š **Advanced Features:** Built-in Retrieval-Augmented Generation (RAG), OCR, audio transcription, and more.
* ğŸŒ **Open Standards:** Compatible with OpenAI APIs, LangChain, and LlamaIndex.
* ğŸ› ï¸ **Deployment Flexibility:** Host generative AI securely on your own infrastructure, ensuring full data sovereignty.

## ğŸ¯ Key Features

### API Gateway

* **Unified Access:** Single API gateway for multiple generative AI model backends:

  * **OpenAI** (Language, Embeddings, Reranking, Transcription)
  * **vLLM** (Language)
  * **HuggingFace TEI** (Embeddings, Reranking)

### Advanced AI Capabilities

* **RAG Integration:** Efficiently query vector databases using Elasticsearch or Qdrant.
* **Audio & Vision:** Transcribe audio (Whisper) and perform OCR on PDF documents.
* **Enhanced Security:** Built-in API key authentication.

## ğŸ“Š Comparison

| Feature              | Albert API âœ… | LiteLLM   | OpenRouter | OpenAI API |
| -------------------- | ------------ | --------- | ---------- | ---------- |
| Fully Open Source    | âœ”ï¸           | Partially | âŒ          | âŒ          |
| Data Sovereignty     | âœ”ï¸           | âœ”ï¸        | âŒ          | âŒ          |
| Multiple AI Backends | âœ”ï¸           | âœ”ï¸        | âœ”ï¸         | âŒ          |
| Built-in RAG         | âœ”ï¸           | âŒ         | âŒ          | âŒ          |
| Built-in OCR         | âœ”ï¸           | âŒ         | âŒ          | âŒ          |
| Audio Transcription  | âœ”ï¸           | âŒ         | âŒ          | âœ”ï¸         |
| Flexible Deployment  | âœ”ï¸           | âœ”ï¸        | âŒ          | âŒ          |
| OpenAI Compatibility | âœ”ï¸           | âœ”ï¸        | âœ”ï¸         | âœ”ï¸         |

## ğŸš€ Quickstart

Deploy Albert API quickly on your own infrastructure:

* [Deployment Guide](./docs/deployment.md)

## ğŸ“˜ Tutorials & Guides

Explore practical use cases:

* [**Chat Completions**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/chat_completions.ipynb)
* [**Multi-Model Access**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/models.ipynb)
* [**Retrieval-Augmented Generation (RAG)**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/retrieval_augmented_generation.ipynb)
* [**Knowledge Database Import**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/import_knowledge_database.ipynb)
* [**Audio Transcriptions**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/audio_transcriptions.ipynb)
* [**PDF OCR**](https://colab.research.google.com/github/etalab-ia/albert-api/blob/main/docs/tutorials/pdf_ocr.ipynb)

## ğŸ¤ Contribute

Albert API thrives on open-source contributions. Join our community!

* [Contribution Guide](./CONTRIBUTING.md)

---

# ğŸ‡«ğŸ‡· Albert API (version franÃ§aise)

**API open source pour modÃ¨les d'IA gÃ©nÃ©rative | Infrastructure souveraine**

Albert API, portÃ© par l'[OPI de la DINUM](https://www.numerique.gouv.fr/dinum/), est le service d'IA gÃ©nÃ©rative de rÃ©fÃ©rence de l'Ã‰tat franÃ§ais, homologuÃ© pour des traitements sÃ©curisÃ©s. Il propose une solution prÃªte pour la production destinÃ©e Ã  lâ€™hÃ©bergement souverain et performant dâ€™IA gÃ©nÃ©ratives avancÃ©es sur votre infrastructure.

## Points forts

* ğŸ” SÃ©curitÃ© et souverainetÃ© des donnÃ©es
* ğŸ§© API unique compatible OpenAI, vLLM et HuggingFace
* ğŸ” Recherche avancÃ©e par RAG et vector stores

Consultez la [documentation](https://albert.api.etalab.gouv.fr/documentation) ou dÃ©ployez rapidement votre instance via le [guide de dÃ©ploiement](./docs/deployment.md).

[Contribuez au projet !](./CONTRIBUTING.md)
